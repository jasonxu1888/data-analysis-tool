{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlsxwriter in c:\\users\\trifo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\trifo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import xlsxwriter     \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.precision\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------CV Stuff---------------------------------------------------------------#\n",
    "\n",
    "############ ENTER ALL FILES, ONLY SEGMENT 5 FILES ALLOWED ############\n",
    "FileList = ['Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-16 1000 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-17 900 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-18 800 mV-s.txt', \n",
    "'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-19 700 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-20 600 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-21 500 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-22 400 mV-s.txt',\n",
    "'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-23 300 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-24 200 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-25 175 mV-s.txt',\n",
    "'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-26 150 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-27 125 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-28 100 mV-s.txt',\n",
    "'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-29 75 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-30 50 mV-s.txt', 'Fe2O3-NC-packed-Au-CME_#1 iR-comp CV-31 25 mV-s.txt']\n",
    "############\n",
    "\n",
    "############ Name of the outputted Excel file ############\n",
    "ExcelFileOutputName = 'CV Data'\n",
    "############\n",
    "\n",
    "############ Fill in RHE constant\n",
    "PotentialConstant = 0.676\n",
    "############\n",
    "\n",
    "############ Fill in capacitance calculation constants\n",
    "Beginning = 0.4\n",
    "End = 0.2\n",
    "DeltaV = Beginning - End\n",
    "############\n",
    "\n",
    "############ FILL IN starting and ending x-value of integration for the peak ABOVE x-axis (from left to right of x-axis) ############\n",
    "TopStartingIntegrationXValue = 0.416\n",
    "TopEndingIntegrationXValue = 0.866\n",
    "############\n",
    "\n",
    "############ FILL IN starting and ending x-value of integration for the peak BELOW the x-axis (from left to right of x-axis) ############\n",
    "BottomStartingIntegrationXValue = 0.416\n",
    "BottomEndingIntegrationXValue = 0.866\n",
    "###########\n",
    "\n",
    "DataFrameListBeforeTreatment = []\n",
    "DataFrameList = []\n",
    "ScanRateList = []\n",
    "\n",
    "for file in FileList:\n",
    "    df = pd.read_csv(file)\n",
    "    DataFrameList.append(df)\n",
    "\n",
    "    for rowidx in range(df.shape[0]):\n",
    "        if ''.join(x for x in df.iloc[rowidx, 0] if not x.isdigit() and x not in '.').strip() == \"Scan Rate (V/s) =\":\n",
    "            ScanRateList.append(float(''.join(x for x in df.iloc[rowidx, 0] if x.isdigit() or x in '.')))\n",
    "            break\n",
    "\n",
    "    CycleEndValue = df.iloc[-1, 0]\n",
    "    for rowidx in range(df.shape[0] - 2, -1, -1):\n",
    "        if df.iloc[rowidx, 0] == CycleEndValue:\n",
    "            CycleBeginning = rowidx\n",
    "            break\n",
    "    df.drop(df.index[0:CycleBeginning - 1], inplace = True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "    df.iloc[:, 0] = pd.to_numeric(df.iloc[:, 0])\n",
    "    df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1])\n",
    "    df.columns = ['Potential/V', 'Current/I']\n",
    "    DataFrameListBeforeTreatment.append(df.copy(deep = True))\n",
    "    df.columns = ['Potential/V vs RHE', 'Current/I']\n",
    "    df.iloc[:, 0] += PotentialConstant\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].round(3)\n",
    "    df.iloc[:, 1] = df.iloc[:, 1]\n",
    "    \n",
    "#---------------------------------------------------------------Capacitance Calculation Portion---------------------------------------------------------------#\n",
    "\n",
    "ForwardCapacitanceList = []\n",
    "BackwardCapacitanceList = []\n",
    "TotalChargeList = []\n",
    "TotalCapacitanceList = []\n",
    "\n",
    "for index, dataframe in enumerate(DataFrameList):\n",
    "    forwardcapacitance = 0\n",
    "    for rowidx in range(dataframe.shape[0]):\n",
    "        if dataframe.iloc[rowidx, 0] >= End:\n",
    "            forwardcapacitance += (dataframe.iloc[rowidx - 2, 0] - dataframe.iloc[rowidx - 1, 0]) * (dataframe.iloc[rowidx - 2, 1] + dataframe.iloc[rowidx - 1, 1])/ (2 * ScanRateList[index])\n",
    "            if dataframe.iloc[rowidx, 0] >= Beginning:\n",
    "                break\n",
    "    ForwardCapacitanceList.append(forwardcapacitance)\n",
    "\n",
    "for index, dataframe in enumerate(DataFrameList):\n",
    "    backwardcapacitance = 0\n",
    "    for rowidx in range(dataframe.shape[0] - 1, -1, -1):\n",
    "        if dataframe.iloc[rowidx, 0] >= End:\n",
    "            backwardcapacitance += (dataframe.iloc[rowidx - 2, 0] - dataframe.iloc[rowidx - 1, 0]) * (dataframe.iloc[rowidx - 2, 1] + dataframe.iloc[rowidx - 1, 1])/ (2 * ScanRateList[index])\n",
    "            if dataframe.iloc[rowidx, 0] >= Beginning:\n",
    "                break\n",
    "    BackwardCapacitanceList.append(backwardcapacitance)\n",
    "\n",
    "for idx in range(len(FileList)):\n",
    "    TotalCapacitanceList.append(abs((ForwardCapacitanceList[idx] + BackwardCapacitanceList[idx]) / (2 * DeltaV)))\n",
    "    TotalChargeList.append(abs(ForwardCapacitanceList[idx] + BackwardCapacitanceList[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------Integral AND Peak Calculation Portion---------------------------------------------------------------#\n",
    "\n",
    "TopCurveCalculation = []\n",
    "TopLineCalculation = []\n",
    "TopIntegralFinalValues = []\n",
    "\n",
    "BottomCurveCalculation = []\n",
    "BottomLineCalculation = []\n",
    "BottomIntegralFinalValues = []\n",
    "\n",
    "Top_MaximumCurrentValue = []\n",
    "Top_RHEValueOfMax = []\n",
    "\n",
    "Bottom_MaximumCurrentValue = []\n",
    "Bottom_RHEValueOfMax = []\n",
    "\n",
    "#Top Integral Calculation\n",
    "for idx in range(len(FileList)):\n",
    "    TopCurveValue = 0\n",
    "    TopLineValue = 0\n",
    "    TopStartRowIndex = None\n",
    "    TopEndRowIndex = None\n",
    "    normaldf = DataFrameList[idx]\n",
    "    modifieddf = normaldf.copy(deep = True)\n",
    "    \n",
    "\n",
    "    for rowidx in range(df.shape[0]):\n",
    "        if (normaldf.iloc[rowidx, 0] == TopStartingIntegrationXValue):\n",
    "            TopStartRowIndex = rowidx\n",
    "            break\n",
    "    for rowidx in range(df.shape[0]):\n",
    "        if (normaldf.iloc[rowidx, 0] == TopEndingIntegrationXValue):\n",
    "            TopEndRowIndex = rowidx\n",
    "            break\n",
    "\n",
    "    slope = (normaldf.iloc[TopEndRowIndex, 1] - normaldf.iloc[TopStartRowIndex, 1]) / (normaldf.iloc[TopEndRowIndex, 0] - normaldf.iloc[TopStartRowIndex, 0])\n",
    "    yintercept = normaldf.iloc[TopEndRowIndex, 1] - (slope * normaldf.iloc[TopEndRowIndex, 0])\n",
    "    for rowidx in range(TopStartRowIndex, TopEndRowIndex + 1):\n",
    "        modifieddf.iloc[rowidx, 1] = (slope * normaldf.iloc[rowidx, 0]) + yintercept\n",
    "\n",
    "    for rowidx in range(normaldf.shape[0]):\n",
    "        if normaldf.iloc[rowidx, 0] >= TopStartingIntegrationXValue:\n",
    "            TopCurveValue += (normaldf.iloc[rowidx - 2, 0] - normaldf.iloc[rowidx - 1, 0]) * (normaldf.iloc[rowidx - 2, 1] + normaldf.iloc[rowidx - 1, 1]) / (2 * ScanRateList[idx])\n",
    "            if normaldf.iloc[rowidx, 0] >= TopEndingIntegrationXValue:\n",
    "                break\n",
    "    TopCurveCalculation.append(abs(TopCurveValue))\n",
    "\n",
    "    for rowidx in range(modifieddf.shape[0]):\n",
    "        if modifieddf.iloc[rowidx, 0] >= TopStartingIntegrationXValue:\n",
    "            TopLineValue += (modifieddf.iloc[rowidx - 2, 0] - modifieddf.iloc[rowidx - 1, 0]) * (modifieddf.iloc[rowidx - 2, 1] + modifieddf.iloc[rowidx - 1, 1]) / (2 * ScanRateList[idx])\n",
    "            if modifieddf.iloc[rowidx, 0] >= TopEndingIntegrationXValue:\n",
    "                break\n",
    "    TopLineCalculation.append(abs(TopLineValue))\n",
    "\n",
    "    #Calculation for the top peak with the background subtracted\n",
    "    Finding_Max_df = normaldf.loc[(normaldf['Potential/V vs RHE'] >= TopStartingIntegrationXValue) & (normaldf['Potential/V vs RHE'] <=TopEndingIntegrationXValue)]\n",
    "    Value_Of_Max = Finding_Max_df['Current/I'].max()\n",
    "    Index_Of_Max = Finding_Max_df['Current/I'].idxmax()\n",
    "    NormalizedMaxValue = Value_Of_Max - modifieddf.iloc[Index_Of_Max, 1]\n",
    "    Top_MaximumCurrentValue.append(NormalizedMaxValue)\n",
    "    Top_RHEValueOfMax.append(Finding_Max_df['Potential/V vs RHE'].loc[Index_Of_Max])\n",
    "\n",
    "#Bottom Integral Calculation\n",
    "for idx in range(len(FileList)):\n",
    "    BottomCurveValue = 0\n",
    "    BottomLineValue = 0\n",
    "    BottomStartRowIndex = None\n",
    "    BottomEndRowIndex = None\n",
    "    regulardf = DataFrameList[idx]\n",
    "    altereddf = regulardf.copy(deep=True)\n",
    "\n",
    "    for rowidx in range(normaldf.shape[0] - 1, -1, -1):\n",
    "        if regulardf.iloc[rowidx, 0] == BottomStartingIntegrationXValue:\n",
    "            BottomStartRowIndex = rowidx\n",
    "            break\n",
    "    \n",
    "    for rowidx in range(normaldf.shape[0] - 1, -1, -1):\n",
    "        if regulardf.iloc[rowidx, 0] == BottomEndingIntegrationXValue:\n",
    "            BottomEndRowIndex = rowidx\n",
    "            break\n",
    "    \n",
    "    otherslope = (regulardf.iloc[BottomEndRowIndex, 1] - regulardf.iloc[BottomStartRowIndex, 1]) / (regulardf.iloc[BottomEndRowIndex, 0] - regulardf.iloc[BottomStartRowIndex, 0])\n",
    "    otheryintercept = regulardf.iloc[BottomEndRowIndex, 1] - (otherslope * regulardf.iloc[BottomEndRowIndex, 0])\n",
    "\n",
    "    for rowidx in range(BottomStartRowIndex, BottomEndRowIndex - 1, -1):\n",
    "        altereddf.iloc[rowidx, 1] = (otherslope * regulardf.iloc[rowidx, 0]) + otheryintercept\n",
    "\n",
    "    for rowidx in range(regulardf.shape[0] - 1, -1, -1):\n",
    "        if regulardf.iloc[rowidx, 0] >= BottomStartingIntegrationXValue:\n",
    "            BottomCurveValue += (regulardf.iloc[rowidx - 2, 0] - regulardf.iloc[rowidx - 1, 0]) * (regulardf.iloc[rowidx - 2, 1] + regulardf.iloc[rowidx - 1, 1]) / (2 * ScanRateList[idx])\n",
    "            if regulardf.iloc[rowidx, 0] >= BottomEndingIntegrationXValue:\n",
    "                \n",
    "                break\n",
    "    BottomCurveCalculation.append(abs(BottomCurveValue))\n",
    "\n",
    "    for rowidx in range(altereddf.shape[0] - 1, -1, -1):\n",
    "        if altereddf.iloc[rowidx, 0] >= BottomStartingIntegrationXValue:\n",
    "            BottomLineValue += (altereddf.iloc[rowidx - 2, 0] - altereddf.iloc[rowidx - 1, 0]) * (altereddf.iloc[rowidx - 2, 1] + altereddf.iloc[rowidx - 1, 1]) / (2 * ScanRateList[idx])\n",
    "            if altereddf.iloc[rowidx, 0] >= BottomEndingIntegrationXValue:\n",
    "                break\n",
    "    BottomLineCalculation.append(abs(BottomLineValue))\n",
    "\n",
    "    #Calculation for the bottom peak with the background subtracted\n",
    "    Finding_Min_df = regulardf.loc[(regulardf['Potential/V vs RHE'] >= BottomStartingIntegrationXValue) & (regulardf['Potential/V vs RHE'] <=BottomEndingIntegrationXValue)]\n",
    "    Value_Of_Min = Finding_Min_df['Current/I'].min()\n",
    "    Index_Of_Min = Finding_Min_df['Current/I'].idxmin()\n",
    "    NormalizedMinValue = Value_Of_Min - altereddf.iloc[Index_Of_Min, 1]\n",
    "    Bottom_MaximumCurrentValue.append(NormalizedMinValue)\n",
    "    Bottom_RHEValueOfMax.append(Finding_Min_df['Potential/V vs RHE'].loc[Index_Of_Min])\n",
    "\n",
    "for idx in range(len(FileList)):\n",
    "    TopIntegralFinalValues.append(abs(TopCurveCalculation[idx] - TopLineCalculation[idx]))\n",
    "    BottomIntegralFinalValues.append(abs(BottomCurveCalculation[idx] - BottomLineCalculation[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------------------------------------------------Outputting to Excel File---------------------------------------------------------------#\n",
    "\n",
    "ExcelFileOutputName = ExcelFileOutputName + '.xlsx'\n",
    "SheetName = 'CV Data'\n",
    "writer = pd.ExcelWriter(ExcelFileOutputName, engine='xlsxwriter')\n",
    "\n",
    "#Inserting dataframes of first cycle of data (segments 4-5)\n",
    "freecolumn = 0\n",
    "freerow = 2005\n",
    "for idx in range(len(FileList)):\n",
    "    DataFrameListBeforeTreatment[idx].to_excel(writer, sheet_name = SheetName, index = False, startrow = 2, startcol = freecolumn)\n",
    "    freecolumn += len(DataFrameListBeforeTreatment[idx].columns)\n",
    "    DataFrameList[idx].to_excel(writer, sheet_name = SheetName, index = False, startrow = 2, startcol = freecolumn)\n",
    "    freecolumn += len(DataFrameListBeforeTreatment[idx].columns) + 2\n",
    "\n",
    "#Putting name of each file above dataframe in Excel file, as well as what segments the data is for\n",
    "Legend = [] \n",
    "for file in FileList:\n",
    "    name = file[0:len(file) - 4]\n",
    "    Legend.append(name)\n",
    "worksheet = writer.sheets[SheetName]\n",
    "column = 0\n",
    "for idx in range(len(FileList)):\n",
    "    worksheet.write_string(0, column, Legend[idx])\n",
    "    column += len(DataFrameListBeforeTreatment[idx].columns) + len(DataFrameListBeforeTreatment[idx].columns) + 2\n",
    "\n",
    "column = 0\n",
    "for idx in range(len(FileList)):\n",
    "    worksheet.write_string(1, column, 'Segments 4-5')\n",
    "    column += len(DataFrameListBeforeTreatment[idx].columns) + len(DataFrameListBeforeTreatment[idx].columns) + 2\n",
    "\n",
    "\n",
    "#Inserting graph of first cycle of data (segments 4-5)\n",
    "workbook = writer.book\n",
    "chart = workbook.add_chart({'type': 'scatter', 'subtype': 'smooth'})\n",
    "namecol = 0\n",
    "categorycol = 2\n",
    "valuescol = 3\n",
    "for idx in range(len(FileList)):\n",
    "    chart.add_series({\n",
    "        'name': [SheetName, 0, namecol, 0, namecol],\n",
    "        'categories': [SheetName, 3, categorycol, 3 + len(DataFrameList[idx]) - 1, categorycol],\n",
    "        'values': [SheetName, 3,  valuescol, 3 + len(DataFrameList[idx]) - 1, valuescol],\n",
    "    })\n",
    "    namecol += 6\n",
    "    categorycol += 6\n",
    "    valuescol += 6\n",
    "chart.set_title({'name': 'All CVs (Segments 4-5)'})\n",
    "chart.set_x_axis({'min': 0, 'max': 1, 'name': 'Potential, V vs RHE'})\n",
    "chart.set_y_axis({'name': 'Current, A'})\n",
    "worksheet.insert_chart(0, freecolumn, chart)\n",
    "\n",
    "#Inserting calculation table of first cycle of data (segments 4-5) \n",
    "TableHeader = []\n",
    "for idx in range(len(FileList)):\n",
    "    ForwardCapacitanceList[idx] = abs(ForwardCapacitanceList[idx])\n",
    "    BackwardCapacitanceList[idx] = abs(BackwardCapacitanceList[idx])\n",
    "    TableHeader.append(Legend[idx][34:])\n",
    "TableList = [ScanRateList, ForwardCapacitanceList, BackwardCapacitanceList, TotalChargeList, TotalCapacitanceList, TopIntegralFinalValues, BottomIntegralFinalValues, Top_RHEValueOfMax, Top_MaximumCurrentValue, Bottom_RHEValueOfMax, Bottom_MaximumCurrentValue]\n",
    "dftable = pd.DataFrame(TableList).T\n",
    "dftable.columns = ['Scan Rate (V/s)', 'Double Layer Charge Pos (mA)', 'Double Layer Charge Neg (mA)', 'Total Charge (mA)', 'Capacitance (mF)', 'Top Charge (mCs)', 'Bottom Charge (mCs)', 'Epa', 'Ipa', 'Eca', 'Ica']\n",
    "dftable.index = TableHeader\n",
    "dftable.to_excel(writer, sheet_name = SheetName, startrow = 32, startcol = freecolumn)\n",
    "worksheet.write_string(31, freecolumn, 'Segments 4-5 Table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is just repeating the process above, except for segments 2-3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrameListBeforeTreatment = []\n",
    "DataFrameList = []\n",
    "ScanRateList = []\n",
    "\n",
    "for file in FileList:\n",
    "    df = pd.read_csv(file)\n",
    "    DataFrameList.append(df)\n",
    "\n",
    "    for rowidx in range(df.shape[0]):\n",
    "        if ''.join(x for x in df.iloc[rowidx, 0] if not x.isdigit() and x not in '.').strip() == \"Scan Rate (V/s) =\":\n",
    "            ScanRateList.append(float(''.join(x for x in df.iloc[rowidx, 0] if x.isdigit() or x in '.')))\n",
    "            break\n",
    "\n",
    "    CycleEndValue = df.iloc[-1, 0]\n",
    "    for rowidx in range(df.shape[0] - 2, -1, -1):\n",
    "        if df.iloc[rowidx, 0] == CycleEndValue:\n",
    "            CycleBeginning = rowidx\n",
    "            break\n",
    "    df.drop(df.index[CycleBeginning - 1:], inplace = True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "    CycleEndValue = df.iloc[-1, 0]\n",
    "    for rowidx in range(df.shape[0] - 2, -1, -1):\n",
    "        if df.iloc[rowidx, 0] == CycleEndValue:\n",
    "            CycleBeginning = rowidx\n",
    "            break\n",
    "    df.drop(df.index[0:CycleBeginning - 1], inplace = True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "    df.iloc[:, 0] = pd.to_numeric(df.iloc[:, 0])\n",
    "    df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1])\n",
    "    df.columns = ['Potential/V', 'Current/I']\n",
    "    DataFrameListBeforeTreatment.append(df.copy(deep = True))\n",
    "    df.columns = ['Potential/V vs RHE', 'Current/I']\n",
    "    df.iloc[:, 0] += PotentialConstant\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].round(3)\n",
    "    df.iloc[:, 1] = df.iloc[:, 1]\n",
    "\n",
    "ForwardCapacitanceList = []\n",
    "BackwardCapacitanceList = []\n",
    "TotalChargeList = []\n",
    "TotalCapacitanceList = []\n",
    "\n",
    "for index, dataframe in enumerate(DataFrameList):\n",
    "    forwardcapacitance = 0\n",
    "    for rowidx in range(dataframe.shape[0]):\n",
    "        if dataframe.iloc[rowidx, 0] >= End:\n",
    "            forwardcapacitance += (dataframe.iloc[rowidx - 2, 0] - dataframe.iloc[rowidx - 1, 0]) * (dataframe.iloc[rowidx - 2, 1] + dataframe.iloc[rowidx - 1, 1])/ (2 * ScanRateList[index])\n",
    "            if dataframe.iloc[rowidx, 0] >= Beginning:\n",
    "                break\n",
    "    ForwardCapacitanceList.append(forwardcapacitance)\n",
    "\n",
    "for index, dataframe in enumerate(DataFrameList):\n",
    "    backwardcapacitance = 0\n",
    "    for rowidx in range(dataframe.shape[0] - 1, -1, -1):\n",
    "        if dataframe.iloc[rowidx, 0] >= End:\n",
    "            backwardcapacitance += (dataframe.iloc[rowidx - 2, 0] - dataframe.iloc[rowidx - 1, 0]) * (dataframe.iloc[rowidx - 2, 1] + dataframe.iloc[rowidx - 1, 1])/ (2 * ScanRateList[index])\n",
    "            if dataframe.iloc[rowidx, 0] >= Beginning:\n",
    "                break\n",
    "    BackwardCapacitanceList.append(backwardcapacitance)\n",
    "\n",
    "for idx in range(len(FileList)):\n",
    "    TotalCapacitanceList.append(abs((ForwardCapacitanceList[idx] + BackwardCapacitanceList[idx]) / (2 * DeltaV)))\n",
    "    TotalChargeList.append(abs(ForwardCapacitanceList[idx] + BackwardCapacitanceList[idx]))\n",
    "\n",
    "TopCurveCalculation = []\n",
    "TopLineCalculation = []\n",
    "TopIntegralFinalValues = []\n",
    "\n",
    "BottomCurveCalculation = []\n",
    "BottomLineCalculation = []\n",
    "BottomIntegralFinalValues = []\n",
    "\n",
    "Top_MaximumCurrentValue = []\n",
    "Top_RHEValueOfMax = []\n",
    "\n",
    "Bottom_MaximumCurrentValue = []\n",
    "Bottom_RHEValueOfMax = []\n",
    "\n",
    "for idx in range(len(FileList)):\n",
    "    TopCurveValue = 0\n",
    "    TopLineValue = 0\n",
    "    TopStartRowIndex = None\n",
    "    TopEndRowIndex = None\n",
    "    normaldf = DataFrameList[idx]\n",
    "    modifieddf = normaldf.copy(deep = True)\n",
    "\n",
    "    for rowidx in range(df.shape[0]):\n",
    "        if (normaldf.iloc[rowidx, 0] == TopStartingIntegrationXValue):\n",
    "            TopStartRowIndex = rowidx\n",
    "            break\n",
    "    for rowidx in range(df.shape[0]):\n",
    "        if (normaldf.iloc[rowidx, 0] == TopEndingIntegrationXValue):\n",
    "            TopEndRowIndex = rowidx\n",
    "            break\n",
    "\n",
    "    slope = (normaldf.iloc[TopEndRowIndex, 1] - normaldf.iloc[TopStartRowIndex, 1]) / (normaldf.iloc[TopEndRowIndex, 0] - normaldf.iloc[TopStartRowIndex, 0])\n",
    "    yintercept = normaldf.iloc[TopEndRowIndex, 1] - (slope * normaldf.iloc[TopEndRowIndex, 0])\n",
    "    for rowidx in range(TopStartRowIndex, TopEndRowIndex + 1):\n",
    "        modifieddf.iloc[rowidx, 1] = (slope * normaldf.iloc[rowidx, 0]) + yintercept\n",
    "\n",
    "    for rowidx in range(normaldf.shape[0]):\n",
    "        if normaldf.iloc[rowidx, 0] >= TopStartingIntegrationXValue:\n",
    "            TopCurveValue += (normaldf.iloc[rowidx - 2, 0] - normaldf.iloc[rowidx - 1, 0]) * (normaldf.iloc[rowidx - 2, 1] + normaldf.iloc[rowidx - 1, 1]) / (2 * ScanRateList[idx])\n",
    "            if normaldf.iloc[rowidx, 0] >= TopEndingIntegrationXValue:\n",
    "                break\n",
    "    TopCurveCalculation.append(abs(TopCurveValue))\n",
    "\n",
    "    for rowidx in range(modifieddf.shape[0]):\n",
    "        if modifieddf.iloc[rowidx, 0] >= TopStartingIntegrationXValue:\n",
    "            TopLineValue += (modifieddf.iloc[rowidx - 2, 0] - modifieddf.iloc[rowidx - 1, 0]) * (modifieddf.iloc[rowidx - 2, 1] + modifieddf.iloc[rowidx - 1, 1]) / (2 * ScanRateList[idx])\n",
    "            if modifieddf.iloc[rowidx, 0] >= TopEndingIntegrationXValue:\n",
    "                break\n",
    "    TopLineCalculation.append(abs(TopLineValue))\n",
    "\n",
    "    #Calculation for the top peak with the background subtracted\n",
    "    Finding_Max_df = normaldf.loc[(normaldf['Potential/V vs RHE'] >= TopStartingIntegrationXValue) & (normaldf['Potential/V vs RHE'] <=TopEndingIntegrationXValue)]\n",
    "    Value_Of_Max = Finding_Max_df['Current/I'].max()\n",
    "    Index_Of_Max = Finding_Max_df['Current/I'].idxmax()\n",
    "    NormalizedMaxValue = Value_Of_Max - modifieddf.iloc[Index_Of_Max, 1]\n",
    "    Top_MaximumCurrentValue.append(NormalizedMaxValue)\n",
    "    Top_RHEValueOfMax.append(Finding_Max_df['Potential/V vs RHE'].loc[Index_Of_Max])\n",
    "\n",
    "for idx in range(len(FileList)):\n",
    "    BottomCurveValue = 0\n",
    "    BottomLineValue = 0\n",
    "    BottomStartRowIndex = None\n",
    "    BottomEndRowIndex = None\n",
    "    regulardf = DataFrameList[idx]\n",
    "    altereddf = regulardf.copy(deep=True)\n",
    "\n",
    "    for rowidx in range(normaldf.shape[0] - 1, -1, -1):\n",
    "        if regulardf.iloc[rowidx, 0] == BottomStartingIntegrationXValue:\n",
    "            BottomStartRowIndex = rowidx\n",
    "            break\n",
    "    \n",
    "    for rowidx in range(normaldf.shape[0] - 1, -1, -1):\n",
    "        if regulardf.iloc[rowidx, 0] == BottomEndingIntegrationXValue:\n",
    "            BottomEndRowIndex = rowidx\n",
    "            break\n",
    "    \n",
    "    otherslope = (regulardf.iloc[BottomEndRowIndex, 1] - regulardf.iloc[BottomStartRowIndex, 1]) / (regulardf.iloc[BottomEndRowIndex, 0] - regulardf.iloc[BottomStartRowIndex, 0])\n",
    "    otheryintercept = regulardf.iloc[BottomEndRowIndex, 1] - (otherslope * regulardf.iloc[BottomEndRowIndex, 0])\n",
    "\n",
    "    for rowidx in range(BottomStartRowIndex, BottomEndRowIndex - 1, -1):\n",
    "        altereddf.iloc[rowidx, 1] = (otherslope * regulardf.iloc[rowidx, 0]) + otheryintercept\n",
    "\n",
    "    for rowidx in range(regulardf.shape[0] - 1, -1, -1):\n",
    "        if regulardf.iloc[rowidx, 0] >= BottomStartingIntegrationXValue:\n",
    "            BottomCurveValue += (regulardf.iloc[rowidx - 2, 0] - regulardf.iloc[rowidx - 1, 0]) * (regulardf.iloc[rowidx - 2, 1] + regulardf.iloc[rowidx - 1, 1]) / (2 * ScanRateList[idx])\n",
    "            if regulardf.iloc[rowidx, 0] >= BottomEndingIntegrationXValue:\n",
    "                \n",
    "                break\n",
    "    BottomCurveCalculation.append(abs(BottomCurveValue))\n",
    "\n",
    "    for rowidx in range(altereddf.shape[0] - 1, -1, -1):\n",
    "        if altereddf.iloc[rowidx, 0] >= BottomStartingIntegrationXValue:\n",
    "            BottomLineValue += (altereddf.iloc[rowidx - 2, 0] - altereddf.iloc[rowidx - 1, 0]) * (altereddf.iloc[rowidx - 2, 1] + altereddf.iloc[rowidx - 1, 1]) / (2 * ScanRateList[idx])\n",
    "            if altereddf.iloc[rowidx, 0] >= BottomEndingIntegrationXValue:\n",
    "                break\n",
    "    BottomLineCalculation.append(abs(BottomLineValue))\n",
    "\n",
    "    #Calculation for the bottom peak with the background subtracted\n",
    "    Finding_Min_df = regulardf.loc[(regulardf['Potential/V vs RHE'] >= BottomStartingIntegrationXValue) & (regulardf['Potential/V vs RHE'] <=BottomEndingIntegrationXValue)]\n",
    "    Value_Of_Min = Finding_Min_df['Current/I'].min()\n",
    "    Index_Of_Min = Finding_Min_df['Current/I'].idxmin()\n",
    "    NormalizedMinValue = Value_Of_Min - altereddf.iloc[Index_Of_Min, 1]\n",
    "    Bottom_MaximumCurrentValue.append(NormalizedMinValue)\n",
    "    Bottom_RHEValueOfMax.append(Finding_Min_df['Potential/V vs RHE'].loc[Index_Of_Min])\n",
    "    \n",
    "for idx in range(len(FileList)):\n",
    "    TopIntegralFinalValues.append(abs(TopCurveCalculation[idx] - TopLineCalculation[idx]))\n",
    "    BottomIntegralFinalValues.append(abs(BottomCurveCalculation[idx] - BottomLineCalculation[idx]))\n",
    "\n",
    "freecolumn = 0\n",
    "for idx in range(len(FileList)):\n",
    "    DataFrameListBeforeTreatment[idx].to_excel(writer, sheet_name = SheetName, index = False, startrow = freerow, startcol = freecolumn)\n",
    "    freecolumn += len(DataFrameListBeforeTreatment[idx].columns)\n",
    "    DataFrameList[idx].to_excel(writer, sheet_name = SheetName, index = False, startrow = freerow, startcol = freecolumn)\n",
    "    freecolumn += len(DataFrameListBeforeTreatment[idx].columns) + 2\n",
    "\n",
    "column = 0\n",
    "for idx in range(len(FileList)):\n",
    "    worksheet.write_string(freerow - 1, column, 'Segments 2-3')\n",
    "    column += len(DataFrameListBeforeTreatment[idx].columns) + len(DataFrameListBeforeTreatment[idx].columns) + 2\n",
    "\n",
    "chart = workbook.add_chart({'type': 'scatter', 'subtype': 'smooth'})\n",
    "namecol = 0\n",
    "categorycol = 2\n",
    "valuescol = 3\n",
    "for idx in range(len(FileList)):\n",
    "    chart.add_series({\n",
    "        'name': [SheetName, 0, namecol, 0, namecol],\n",
    "        'categories': [SheetName, 2006, categorycol, 2006 + len(DataFrameList[idx]) - 1, categorycol],\n",
    "        'values': [SheetName, 2006,  valuescol, 2006 + len(DataFrameList[idx]) - 1, valuescol],\n",
    "    })\n",
    "    namecol += 6\n",
    "    categorycol += 6\n",
    "    valuescol += 6\n",
    "chart.set_title({'name': 'All CVs (Segments 2-3)'})\n",
    "chart.set_x_axis({'min': 0, 'max': 1, 'name': 'Potential, V vs RHE'})\n",
    "chart.set_y_axis({'name': 'Current, A'})\n",
    "worksheet.insert_chart(16, freecolumn, chart)\n",
    "\n",
    "TableHeader = []\n",
    "for idx in range(len(FileList)):\n",
    "    ForwardCapacitanceList[idx] = abs(ForwardCapacitanceList[idx])\n",
    "    BackwardCapacitanceList[idx] = abs(BackwardCapacitanceList[idx])\n",
    "    TableHeader.append(Legend[idx][34:])\n",
    "TableList = [ScanRateList, ForwardCapacitanceList, BackwardCapacitanceList, TotalChargeList, TotalCapacitanceList, TopIntegralFinalValues, BottomIntegralFinalValues, Top_RHEValueOfMax, Top_MaximumCurrentValue, Bottom_RHEValueOfMax, Bottom_MaximumCurrentValue]\n",
    "dftable = pd.DataFrame(TableList).T\n",
    "dftable.columns = ['Scan Rate (V/s)', 'Double Layer Charge Pos (mA)', 'Double Layer Charge Neg (mA)', 'Total Charge (mA)', 'Capacitance (mF)', 'Top Charge (mCs)', 'Bottom Charge (mCs)', 'Epa', 'Ipa', 'Eca', 'Ica']\n",
    "dftable.index = TableHeader\n",
    "dftable.to_excel(writer, sheet_name = SheetName, startrow = 32 + len(FileList) + 2, startcol = freecolumn)\n",
    "worksheet.write_string(31 + len(FileList) + 2, freecolumn, 'Segments 2-3  Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6429e7ccc7c3719b21c1bf706142e8020d560237833d6c035ca6dea55fe035c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
